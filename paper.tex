% GigaScience template
\documentclass[a4paper,num-refs]{oup-contemporary}

\journal{gigascience}


%%%% Packages %%%%
\usepackage{siunitx}
\usepackage{minted} % Used for JSON highlighting
\usepackage{algpseudocode} % Algorithmic environment
\usepackage{xspace}
\usepackage{booktabs}

%%%%%%

\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{makecell}
\usepackage[flushleft]{threeparttable}

\usepackage{subcaption}
\usepackage{xspace}
\usepackage{stmaryrd} % for llbracket and rrbracket
\usepackage{amsmath}
\DeclareMathOperator*{\argmin}{argmin}

%%%% Commands %%%%
\newcommand{\todo}[1]{\color{red}\textbf{TODO:}#1\color{black}}
\newcommand{\note}[2]{\color{blue}Note: #1\color{black}}
\newcommand{\reprozip}[0]{ReproZip\xspace}
\newcommand{\tristan}[1]{\color{blue}\textbf{From Tristan:}#1\color{black}}

 
\title{NURM: a tool to 
locate numerical differences in pipelines}
  
\begin{document}

\author[1]{Ali Salari}
\author[1]{Lalet Scaria}
\author[2,3]{Gregory Kiar}
\author[2]{Lindsay Lewis}
\author[2,3]{Alan C. Evans}
\author[1]{Tristan Glatard}

\affil[1]{Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada}
\affil[2]{McGill University, Montreal, Canada}
\affil[3]{Montreal Neurological Institute, Montreal, Canada}

\maketitle

\begin{abstract} 

Many experiments show that computational analysis results are still not 
completely reproducible. Computational environments including different 
operating systems, hardware categories, and software versions are known 
to have effects on the results produced by analysis pipelines. These 
effects are presumably due to the creation, propagation and 
amplification of small numerical differences across the pipelines. 
Although new techniques such as virtualization, version control 
systems, and provenance management tools provide more reliable 
environment and significantly improve the reproducibility of scientific 
findings. However, the precise causes of such instabilities and the 
path along which they propagate in the pipelines are unclear.  We 
present a technique to identify the processes in the pipeline that 
create numerical differences along the execution, and we apply this 
technique to the HCP structural pre-processing pipelines.

\end{abstract}

\begin{keywords}
Reproducibility; Numerical Instability; Neuroimaging.
\end{keywords}

\section{Introduction}

A reproducible study provides a context in which one is able to get 
results that are consistent with the original 
work~\cite{plesser2018reproducibility}. Research findings are expected 
to be reproducible so that their authenticity and reliability can be 
evaluated. 

Reproducibility is defined as the ability to regenerate the same 
results as the original findings when the experiment is reanalyzed by 
exactly the same analytic methods, software package, parameters, and 
data~\cite{peng2011reproducible}. 

In addition, numerical reproducibility is defined as the ability to 
regenerate bit for bit identical results from multiple 
runs~\cite{hill2017numerical}. This Numerical reproducibility can be 
checked by comparing the binary content of the results which is 
computed by the checksum method.
Regarding these definitions, it must be pointed that a
computation might be reproducible, but not 
be numerically reproducible. For instance, small numerical differences 
created during the pipeline execution may hamper numerical 
reproducibility, but be negligible in the final results.

Recently, scientists began to realize that the results of many 
scientific experiments were not reproducible. According to the previous 
studies, variety of computational infrastructures including workstation 
types, parallelization methods, operating systems, and analysis 
packages are known to influence reproducibility~\cite{Gronenschild2012, 
diethelm2012limits, Glatard2015, bowring2019exploring}.

In particular, the effect of operating system is quantified 
in~\cite{Glatard2015, Gronenschild2012} specially on some of the main 
neuroimaging pipelines including FSL, CIVET and FreeSurfer pipelines. 
The binary differences are measured by the checksum method between 
results of the same analyses on different operating systems, which 
indicate a significant disparity. 

This irreproducibility issues are reported as the result of the 
creation, propagation, and amplification of small numerical 
differences~\cite{Gronenschild2012, diethelm2012limits, Glatard2015, 
bowring2019exploring}. In this case, the analysis pipelines are said to 
be numerically unstable. Numerical instability is a characteristic of 
the pipelines which amplify small numerical differences and then hamper 
the reproducibility of the analyses depending on the length of the 
pipeline and magnitude of the differences. In many cases, numerical 
instability is an important issue for reproducibility.

There are different solutions to make reproducible analysis including 
containerization techniques that encapsulate software/hardware 
dependencies, provenance capturing tools, and version control systems. 
However, a comprehensive solution requires to fix the numerical 
instabilities. For this purpose, we introduce a Numerical 
Reproducibility Measurement (NURM) tool to identify the processes in 
pipeline that create numerical differences across several runs. In this 
paper, the execution results of pipelines across different operating 
systems are considered to find out the cause of the irreproducibility 
using the interposition techniques.

The remainder of this paper describes the NURM-tool in different parts 
including the way of capturing and representation of the provenance 
information, the method of clustering of different subject types, and 
process labelling to characterize differences. We describe the HCP 
preprocessing pipelines as a popular neuroimaging project to test the 
NURM-tool and evaluate its functionality. Finally, we reported the 
experimental results which describe the processes that are responsible 
for the differences in the pipelines.

\tristan{define subjects, explain neuroimaging, bring context.}
\section{Tool description}

Figure~\ref{fig:overview} shows an overview of our method. For each tested
condition, Condition 1 and Condition 2, the pipeline is containerized with
Docker, and its interface is described with
Boutiques~\cite{glatard2017boutiques}. \reprozip~\cite{Chirigati2016} is
added to Condition 1 for provenance tracking. Our tool starts by
identifying temporary files and ``multi-write" files, i.e., files written
by more than one process (Figure~\ref{fig:overview-capturing}). To do that,
the tool first executes the pipeline in Condition 1, to obtain a process
graph (Figure~\ref{fig:overview-capturing} - (1)) and a list of result files.
The list of processes that create intermediary or multi-write
files is then generated (Figure~\ref{fig:overview-capturing} - (2)). 
Using this list, the tool modifies Docker image in Condition 1 and
exectutes the pipeline again through it, which turns to produce results
including temporary and overwritten files
(Figure~\ref{fig:overview-capturing} - (3,4)). In the second step, the
processes are labeled from the differences found in their outputs in the
two tested conditions (Figure~\ref{fig:overview-labelling}). To this order,
the tool builds docker image for Condition 2 by modifying pipeline
processes (Figure~\ref{fig:overview-labelling} - (1)) that recognised from 
the process graph. Then, the modified docker
image is executed in Condition 2 and each process is labeled right after
the running by comparing checksum of the results obtained in Condition 1
and output files of the process in Condition 2
(Figure~\ref{fig:overview-labelling} - (2)). We then label processes in 2
categories depending whether they
create differences (represented in red) or not (green). 
The tool replaces output file with the same file obtained in Condition 1 
if process creates differences (Figure~~\ref{fig:overview-labelling} - (3)).
Process labelling
is done through hooks which are defined during the docker image modifying
procedure, and incremental updates in Condition 2, until the end of the
pipeline execution.

\begin{figure}
  \centering
  \begin{subfigure}{\columnwidth}
    \centering
    \includegraphics[width=1\columnwidth]{images/fig1-a}
    \caption{Identification of temporary and multi-write files.
    (\href{https://docs.google.com/drawings/d/1rsbFwPjNPNMRhXUl4RSK3G0OaiJC7K-buiHN0hPD8eQ/edit?usp=sharing}{Source})}
    \label{fig:overview-capturing}
  \end{subfigure}
   \begin{subfigure}{\columnwidth}
    \centering
     \includegraphics[width=1\columnwidth]{images/fig1-b}
     \caption{Labelling process graphs including intermediary files.
     (\href{https://docs.google.com/drawings/d/1yblYuKWAD18aJe5JxBu2h1EysyoQA3YrsQj-1T3s0l8/edit?usp=sharing}{Source})}
     \label{fig:overview-labelling}
   \end{subfigure}
   \caption{An overview of NURM tool in two steps. First capturing intermediary files (a); then
            labelling process graphs (b).}
   \label{fig:overview}
  \end{figure}

\subsection{Provenance capture and representation}

We use \reprozip 
to capture: (1) the set of processes created by the
pipeline, using the \texttt{clone()} or \texttt{fork()} system call, and
(2) the set of files read, written and executed by each process, including
temporary files. \reprozip collects this information through the
\texttt{ptrace()} system call and stores it in a SQLite database.

Our tool reconstructs a \emph{process tree} starting from the first process
created by the pipeline and traversing processes through \texttt{clone()}
and \texttt{fork()} dependencies. Our tool also creates a process \emph{graph} 
(Figure~\ref{fig:overview-capturing} - (1)) from this tree
by adding edges corresponding to file dependencies between processes. A
file dependency is defined between processes A and B if a file written by A
is read by B. Figure~\ref{fig:simple_script} shows an example of a process
tree and graph constructed from the example pipeline in
Listing~\ref{listing:sample-script}.
\begin{listing}
\begin{minted}[frame=single,
  framesep=3mm,
  linenos=false,
  xleftmargin=0pt,
  tabsize=4]{bash}
#!/bin/bash

# This script extracts the brain from an input image,
# measures the volume of the extracted brain,
# and creates a binarized brain mask.

if [ $# != 1 ]
then
    echo "usage: $0 <inputimage.nii.gz>"
    exit 1
fi

# Parse argument, set file names
input_image=$1
bet_output=$(basename "${input_image}" \
                       .nii.gz)_brain.nii.gz
bet_output_binarized=$(basename "${input_image}" \
                       .nii.gz)_brain_bin.nii.gz

# Run FSL bet, put result ${bet_output}
bet "${input_image}" "${bet_output}" > bet_temp.out
echo "Voxels / Volume in brain mask:"
# Run FSL stats on ${bet_output}
fslstats "${bet_output}" -V
# Run FSL maths on ${bet_output}
fslmaths "${bet_output}" "${bet_output_binarized}"
# Remove temporary file
\rm bet_temp.out
\end{minted}
  \caption{Example pipeline}
  \label{listing:sample-script}
\end{listing}

\begin{figure}
\centering
  \includegraphics[width=0.3\columnwidth]{images/simple_graph}
  \caption{Process tree and graph
  constructed from the example pipeline in
  Listing~\ref{listing:sample-script}.
  Processes that read or write
  temporary files are 
  represented with squares. Plain edges 
  represent the process tree (\texttt{fork()} or \texttt{clone()} 
  system calls). Dashed edges represent file dependencies: temporary 
  files are in yellow and result files are in green.
  Every node in the tree is labeled using (1) a process id created by our
  reconstruction, (2) the name of the executable run by the process.
  Process 0 is the initial call to the \texttt{sh} interpreter, and
  processes 1, 3 and 4 are the calls to FSL bet, stats and maths made in
  Listing~\ref{listing:sample-script}. Process 2 is forked by process 1: it
  was captured by \reprozip while it did not appear in
  Listing~\ref{listing:sample-script}. 
}
  \label{fig:simple_script}
\end{figure}


\subsection{Graph analysis}

We label in two categories the processes of the graph of each subject. First,
processes that read files that do not have differences and write files that
do not have differences are labeled \emph{transparent}
(Figure~\ref{fig:green}). Second, processes that read files that do not
have differences but write files that have differences \emph{create}
differences (Figure~\ref{fig:red}). In addition, processes that read files
that have differences and write files that also have differences are called
\emph{undetermined} (Figure~\ref{fig:yellow}). Processes are also labeled
undetermined when they read or write temporary files, or produce multi-write
files. To resolve undetermined processes, hooks must be added to the pipeline to 
execute these processes on files without differences, and to capture
intermediary file states.

\begin{figure}%\centering
\centering
    \begin{subfigure}{0.2\linewidth}
        \includegraphics[scale=0.3]{images/green.png}
        \caption{Transparent}
        \label{fig:green}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.2\linewidth}
    \includegraphics[scale=0.3]{images/red.png}
    \caption{Creates differences}
    \label{fig:red}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.2\linewidth}
    \includegraphics[scale=0.3]{images/yellow.png}
    \caption{Undetermined}
    \label{fig:yellow}
\end{subfigure}
    \caption{Different type of labeled process based on the input/output files.
  Dashed edges refer to the file dependencies between processes A and B 
  if a file written by A is read by B. Solid black edges refer to the 
  relationship between parent and child processes.}
    \label{fig:processes}
\end{figure}

\subsubsection{Capturing temporary files} 

The label of processes that read or 
write temporary files is undetermined because these files are deleted during 
the execution. To address this issue, we replace in Condition 1 every process P that 
writes temporary files with a modification of P that first calls P and then
saves all its output files to a read-only directory. This replacement is
done by modifying the PATH environment variable to point to a directory
containing a modified version of the executable called by the process. The
modified executable will run the original executable and then save its
output files (see Listing~\ref{listing:modify-script}). 
This 
solution does not cover the temporary files that are removed by P 
itself, but this is not a problem since these files do not play any role in 
the subsequent steps of the pipeline. 

\begin{listing}
  \begin{minted}[frame=single,
    framesep=3mm,
    linenos=false,
    xleftmargin=0pt,
    tabsize=4]{python}
  #!/usr/bin/env python
  import os.path as op
  import shutil

  # Run the original executable using the same arguments
  executed_file = sys.argv[0]
  exec_argv = op.join('original_scripts', executed_file)
  exec_argv = exec_argv + " ".join(sys.argv[1:])
  subprocess.Popen(exec_argv, shell=True).communicate()
  
  # Load list of captured process to be checked
  with open('path/to/p_list/', 'r') as p_list:
      process_list = json.load(p_list)

  if exec_argv in process_list.keys():
      # Save output files to read-only directory
      p_files = process_list[exec_argv]
      shutil.copy(p_files, '/read-only/dir')
  
  \end{minted}
    \caption{Modified version of the script in Listing~\ref{listing:sample-script} to save intermediary files.}
    \label{listing:modify-script}
  \end{listing}

\subsubsection{Capturing multi-write files}

Files written by multiple processes also lead 
to undetermined labels. For a file F 
written by all processes in \textbf{P} = \{$P_{1}$, \ldots $P_{n}$\}, we 
(1) check that processes in \textbf{P} do not write concurrently to F, 
(2) we establish an order on \textbf{P} based on the creation timestamp 
of the processes, (3) we replace every process $P_{i}$ in \textbf{P} by 
a wrapper that first calls $P_{i}$ and then saves F to a read-only 
directory. Thus, multiple versions of F are saved and used in the 
analysis. 

Furthermore, cycles may be present in the process graph in case a file 
was written by more than one process. We remove such cycles by removing 
file edges between processes A and B when A's process creation 
timestamp is posterior to B's or when A=B. Indeed, such edges cannot 
happen in practice unless A and B were running concurrently, which we 
assume is not the case (the tool checks for that). 

As an example of this capturing process, in the sample pipeline in 
Listing~\ref{listing:sample-script}, process \texttt{2\#bet2} writes a temporary file and 
also file \emph{T1w\_brain\_bin.nii.gz} is first written by process \texttt{2\#bet2} and 
then overwritten by process \texttt{3\#fslmaths}. The list of these processes is captured in 
Listing~\ref{listing:json_process}.
Using this list, we modify relevant processes in Condition 1 and then re-execute pipeline 
to save them in a backup folder.
Figure~\ref{fig:overview-capturing} - (4) shows pipeline results including intermediary files 
captured as the outputs in Condition 1. 

\begin{listing}
  \begin{minted}[frame=single,
    framesep=3mm,
    linenos=false,
    xleftmargin=0pt,
    tabsize=4]{JSON}
{
  "multi_write_process": {
    "fslmaths\00T1w_brain.nii.gz\00T1w_brain_bin.nii.gz":
    {
      "files":[
        "/cond1/subj1/T1w_brain_bin.nii.gz"
      ],
      "pid": 78
    },
    "bet2\00/cond1/subj1/T1w.nii.gz\00T1w_brain.nii.gz":
    {
      "files":[
        "/cond1/subj1/T1w_brain_bin.nii.gz"
      ],
      "pid": 75
    }
  },
  "temp_process": {
    "bet2\00/cond1/subj1/T1w.nii.gz\00T1w_brain.nii.gz": 
    {
      "files": [
        "/cond1/subj1/temp.tmp"
      ],
      "pid": 75
    } 
  } 
}

\end{minted}
\caption{List of process and their files from the example pipeline in 
Listing~\ref{listing:sample-script} that should be captured.}
\label{listing:json_process}
\end{listing}


\subsubsection{Labelling undetermined processes} 

Since all the result files are captured in Condition 1, the tool 
is ready to label the piepeline processes based on the results in Condition 2.
However, another challenge is to label undetermined processes that read files with 
differences and write files with differences too. In this
situation, it is not possible to determine from the pipeline results 
whether the process created differences or 
was transparent.
To address this issue, we set hooks in the pipeline 
in Condition 2. Hooks are set by replacing the pipeline 
processes with a custom script. This custom script labels each process 
as \emph{transparent} or \emph{create differences} immediately after running 
the original executable. 
The replacement is done through the PATH variable, as before. Moreover, 
this custom script copies the results obtained from the same process in 
Condition 1 to the pipeline output in Condition 2 if 
it is invoked with the arguments of a process that created differences 
(Figure~\ref{fig:overview-labelling} - (3)). 
Differences are identified by comparing checksum of the output files for 
the same process in both conditions (Figure~\ref{fig:overview-labelling} - (2)).
We developed an incremental approach that consists of the following steps: 

\begin{enumerate}
  \item Start the pipeline execution in Condition 2; 
        after hooking all the processes involved in the pipeline.
  \item Label each process as \emph{transparent} or \emph{create differences} 
        right after its running.
  \item Check if process is \emph{create differences} then: 
        copy the results produced by the same process in Condition 1 to the 
        pipeline output in Condition 2. 
  \item Continue steps 2 and 3 until the end of the pipeline execution.
\end{enumerate}

This algorithm creates a \emph{labeled process tree} at the end of pipeline execution 
which highlights processes that create differences.
(Figure~\ref{fig:overview-labelling} - (4)).

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{images/iterative_modif}
  \caption{A simple example of steps of the proposed approach.}
  \label{fig:iterations}
\end{figure}

Figure~\ref{fig:iterations} illustrates our incremental labelling 
process for the example in Figure~\ref{fig:simple_script}. At every 
step, processes that created differences are shown in red and other processes 
(transparent processes) are in green. As in 
Figure~\ref{fig:simple_script}, plain black edges represent the process 
tree and dashed edges represent file dependencies: green edges 
represent files with no differences, while red edges represent files with 
differences. Temporary files are not represented because they have been 
saved as previously described.

The four steps in Figure~\ref{fig:iterations} correspond to the 
steps of the labelling algorithm. 
At step one, process \texttt{1\#bet} is executed and then labeled 
as transparent (green) as it produced files without differences.
At step 2, \texttt{2\#bet2} 
is labeled as difference creator (red) as it produced files with differences 
from files without differences. Therefore, the files produced by \texttt{2\#bet2} in  
Condition 2 are replaced with the files produced by \texttt{2\#bet2} in 
Condition 1.
At step 3, after running process \texttt{3\#fslstats}, it labeled as 
transparent as it write files without differences.
At step 4, process \texttt{4\#fslmaths} is labeled as difference creator 
as the last process of the pipeline.
As a result of these 4 steps, the final process labelling is: 
\texttt{2\#bet2} and \texttt{4\#fslmath} are difference creators (red) 
and the other processes are transparent.


\subsection{Subject clustering}

Different subjects may lead to different \emph{process tree}, due to
variations that may be coming from differences in data types or
cardinality. For instance, some images may have been acquired multiple
times in some subjects. Some of these differences can be neglected, for
instance when a data decompression step is present at the beginning of the
execution for some subjects only, and other ones cannot, when different
processing paths are used in different subjects.

Different \emph{process tree} shows that pipeline execution followed by a different procedure. 
This implies the possible impact of different subjects on pipeline results.
We cluster subjects into different types to specify how many different 
\emph{process trees} are generated. Clustering is performed based on the \emph{process trees} 
which nodes are labeled by the process name. 
In this order, 
the tree edit distance~\cite{zhang1989simple} is used as a similarity measure for 
representing the distance between labeled trees. Tree edit distance  is defined  
as the minimum number of edit operations which is needed to transform one tree into 
the other. Three edit operations are considered: node label modification, 
node removal, and node insertion. Each operation has an associated cost of 1.
With this distance, we cluster subjects using agglomerative hierarchical
clustering as implemented in SciPy~\cite{oliphant2007scipy}
(Algorithm~\ref{algo:hclustering}). As a result, the distance between
any two subjects in a cluster is lower than a threshold parameter.

Furthermore, we will show that even subjects in the same cluster, 
having the same topological \emph{process tree} structure, 
may have different labels as processes that create differences.

\begin{algorithm}[h!]
\caption{Hierarchical clustering algorithm from SciPy}
\label{algo:hclustering}
\begin{algorithmic}

  \State /* Input: - a list of n trees; \texttt{T = [t${_1}$, t${_2}$,...,t${_n}$]}
  \State /*\quad \quad \quad \quad - a distance threshold value; \texttt{threshold}
  \State /* Output: a list of clusters; \texttt{C = [c${_1}$,c${_2}$,...,c${_k}$]}
  \State \texttt{\# Create a cluster for each tree in input list;}
  \State \texttt{C = [ [t${_1}$], [t${_2}$], \ldots , [t${_n}$] ]}
  \State \texttt{\# Define a 2 $\times$ 2 array to store distances}
  \State \texttt{D} = \texttt{array(n, n)}
  \While{\texttt{len(C)} > \texttt{1}}  
  \State \texttt{\# Select the two nearest clusters}
  \For{\texttt{i=1} to \texttt{n}}
  \For{\texttt{j=i+1} to \texttt{len(C)}}
  \State \texttt{D[i][j]} = $\min \left\{ \texttt{edit\_dist(a, b)}: \ \texttt{a} \in \texttt{C[i]}, \texttt{b} \in \texttt{C[j]} \right\}$
    \EndFor
  \EndFor
  \State \texttt{i, j} = $\argmin \left\{ \texttt{D[i][j]}, \ \texttt{i, j} \in \llbracket 1, \texttt{len(C)}\rrbracket^2 \right\}$
  \If{\texttt{D[i][j]} > \texttt{threshold}}
  \State \Return \texttt{C}
  \Else
  \State \texttt{\# Merge C[j] into C[i]}
  \State \texttt{C[i]} = \texttt{merge}(\texttt{C[i] and C[j]})
  \State \texttt{\# Remove C[j] from C}
  \State \texttt{remove(C[j], C)}
  \EndIf
  \EndWhile
%  \State Function edit\_distance (C${_1}$, C${_2}$)
%  \State EndFunction
\end{algorithmic}
\end{algorithm}


\section{Experiments}

The variety of computing infrastructures, particularly operating system, are 
known to influence the reproducibility of computational pipelines because of the
creation of small numerical differences. 
These differences mainly correspond to the mathematical functions implemented 
in different operating system libraries.
For instance, changing the mathematical functions like \emph{expf()} and 
\emph{cosf()} which manipulate the precision of floating-point representations, 
between \emph{glibc} libraries in different operating systems can produce 
small numerical differences.
Furthermore, a similar issue is expected for any operating system which is 
based on \emph{glibc}, the GNU C library.

Indeed, the propagation and amplification of these tiny perturbations by analysis 
pipelines may cause reproducibility issues. We focus on the differences 
created by different version of operating systems in computational pipelines. 
In particular, NURM-tool is tested on the neuroimaging applications which are 
predominantly using mathematical libraries.

\subsection{HCP pipelines and datasets}

The Human Connectome Project (\href{https://www.humanconnectome.org}{HCP}) 
is a significant effort that will acquire and analyze brain connectivity 
data from 1200 healthy adults.
It enables the neuroscience 
research community to discover relationships between brain circuits and 
indivisual behaviors. This helps to understand a wide range of brain disorders.
The HCP project provides (1) database services (ConnectomeDB) for storing and 
sharing primary and processed data freely, and (2) data analysis pipelines that 
are available under an open source license.

The HCP developed a set of pre-processing pipelines to process structural,
functional and diffusion MRI data acquired in the project. We focus on HCP
pre-processing pipelines for structural data, particularly PreFreeSurfer
and FreeSurfer. A detailed description of the analyses done in the
pipelines is available in~\cite{glasser2013}. \TG{Introduce and present all the
pipeline components mentioned in the results, such as BrainExtraction, ACPC alignment, \ldots
The presentation should be at the right level of detail.}
% IF NEEDED, ADD MORE DETAILS ABOUT WHAT THE PIPELINES DO
% The structural pre-processing pipelines consists of PreFreeSurfer, 
% FreeSurfer and PostFreeSurfer. In this paper, 
% we analyzed PreFreeSurfer pipeline which consist of various steps 
% including correction of MR 
% gradient nonlinearity distortions, align the T1w and T2w images using 
% FSL FLIRT, Align native space to MNI template using ACPC and FSL FLIRT, 
% brain extraction usin FSL FLIRT and FNIRT to MNI template, register T2w 
% to T1w using FLIRT's BBR, perform a bias field correction, and register 
% the subject's native structural space to MNI space.
In this paper, we randomly selected 100 unprocessed subjects from the HCP data release S500.
We first quantify the effect of Linux version on
these pipelines. Then we identify the processes in the
pipelines that are responsible for such effects using NURM-tool.


%\begin{figure}
%\centering
%  \includegraphics[width=\columnwidth]{images/overview.png}
%  \caption{An overview of the proposed technique.}
%  \label{fig:overview}
%\end{figure}


%\begin{table}
%\centering
%\begin{threeparttable}
%\caption{An overview of the HCP data (Humman Connectome DB).}
%
%\begin{tabular}{@{}llllll@{}}
%\toprule
%Subject & Release & Acquisition & Gender & Age      & Subj\_Type   \\ \midrule
%103515  & Q1      & Q02         & F      & 26-30    & type1         \\
%105216  & Q3      & Q03         & M      & 26-30    & type4         \\
%103414  & Q2      & Q02         & F      & 22-25    & type1         \\
%125525  & Q1      & Q01         & F      & 31-35    & type1         \\
%142828  & Q1      & Q01         & M      & 31-35    & type1         \\
%129533  & Q3      & Q04         & F      & 31-35    & type1         \\
%103818  & Q1      & Q01         & F      & 31-35    & type3         \\
%133928  & Q2      & Q03         & M      & 26-30    & type3         \\
%148032  & Q3      & Q03         & F      & 31-35    & type2         \\
%139637  & Q2      & Q03         & F      & 31-35    & type1         \\ \bottomrule
%\end{tabular}
%\begin{tablenotes}
%      \small
%      \item *Subj\_Type refers to the tree topology type of the subjects.
%\end{tablenotes}
%\end{threeparttable}
%\label{table:data}
%\end{table}



\section{Results}

We executed the pipelines using Docker containers to simplify the 
deployment of different operating system versions on execution 
platforms. The Docker images were built for the HCP pre-processing 
pipelines v3.19.0 (PreFreeSurfer and FreeSurfer) in 
CentOS 6.8 and CentOS 7.2. Docker images are available on 
\href{https://hub.docker.com/r/bigdatalabteam/hcp-prefreesurfer/}{DockerHub}
for reuse. \TG{Should go to experiments}

Two types of errors can occur in the subjects due to the 
errors in the operating systems. One is inter-OS error caused by the 
operating system library updates and the other type, intra-OS errors 
occurs as a result of the pseudo-random processes used in the 
pipelines. 
We have initialized random number generators using a seed state 
to avoid intra-OS errors in our experiments \TG{how? where?}. 
Therefore, NURM-tool is able to identify the process in the pipelines 
that create differences caused by the inter-OS errors. \TG{Change errors to differences.}
\TG{Check that again, on all subjects.}

\subsubsection{Inter-OS binary differences}

In a previous study~\cite{Scaria2017}, we showed that the HCP pre-processing 
pipelines~\cite{glasser2013} were 
sensitive to operating system variation. Figure 
\ref{fig:tissue_class} illustrates the binarized differences after brain 
tissue segmentation in FreeSurfer. In addition, 
Figure~\ref{fig:fnirt_result} shows the same differences after 
non-linear in PreFreeSurfer. 

\begin{figure}
%  \includegraphics{brain\_classification}
\centering
  \includegraphics[width=\columnwidth]{images/brain_classification.png} 
  \caption{Binarized differences between brain segmentation results from 
           FreeSurfer, subject 105216 (CentOS6 vs. CentOS7)~\cite{Scaria2017}.} 
  \label{fig:tissue_class}
\end{figure}

\begin{figure}
\centering
  \includegraphics[width=\columnwidth]{images/fnirt_result.png} 
  \caption{Absolute differences between FNIRT results from PreFreeSurfer 
  (T2w\_acpc\_to\_MNI\_nonli.nii.gz), subject 104820 (CentOS6 vs. 
  CentOS7)~\cite{Scaria2017}. } 
  \label{fig:fnirt_result}
\end{figure}

\subsubsection{PreFreeSurfer pipeline analysis} 

We clustered subjects into different groups using the NURM-tool, 
after that PreFreeSurfer pipeline has executed on input data.
Figure~\ref{fig:subj-clusters} shows the result of data clustering. \TG{Make a table instead of a figure. 
Mention the threshold and any other clustering parameter.}
Among our dataset, we identified 4 types of subjects with 
different topology of \emph{process trees}. In addition, we verified that 
the \emph{process trees} were identical for all subjects of the same type in 
different versions of CentOS operating system. \TG{Check what these 4 types correspond to}

We identified processes that introduce differences in PreFreeSurfer 
pipeline. 
The processes that introduce differences in PreFreeSurfer along with the 
number of occurrences are depicted in Figure~\ref{fig:pfs_chart} 
including linear registration with “\emph{FLIRT}” (in 
ACPC Alignment, BrainExtraction, DistortionCorrection, 
AtlasRegistration), non-linear registration with “\emph{FNIRT}” (in 
BrainExtraction and AltasRegistration), image warping with 
“\emph{new\_invwarp}” (in BrainExtraction and AtlasRegistration) and 
“\emph{applywarp}” (in DistortionCorrection, BrainExtraction, AtlasRegistration).  
In addition, differences were observed in image mean and standard-deviation 
computations with “\emph{fslstats}” (in BiasFieldCorrection), and in 
masked image extrapolation with “\emph{fslmaths}” (in BiasFieldCorrection). 
Besides, transformation format conversion with 
“\emph{convertwarp}” (in DistortionCorrection) was able to create differences.
It can be seen that \emph{fslmaths}, \emph{applywarp}, and \emph{flirt} 
are the most frequent processes that create differences in the 
PreFreeSurfer pipeline.
\note{add: \emph{wb\_command}}


Furthermore, we determined the frequency of each process that creates differences in 
each pipeline element separately in Figure~\ref{fig:pfs_freq}. It is clear that 
DistortionCorrection element in PreFreeSurfer has the most calls of the processes that 
create differences.
% Among the 117 data files produced by PreFreeSurfer, 21 did 
% not have any error for any subject, 92 had errors for all subjects and 
% 4 had errors for 3 subjects only. 

% Figure \ref{fig:complete-graph} shows the annotated provenance graph 
% of the PreFreeSurfer pipeline executed on CentOS6 and CentOS7. Each 
% node in the graph represent an executed process in the pipeline. 
% Processes that created errors are shown in red, processes that removed 
% errors are in blue, and other processes are in green.  Squares denote 
% processes for which the labelling is uncertain, due to temporary 
% files that were removed during the execution. Black edges link 
% sub-processes to their parents while dashed edges denote file 
% dependencies between processes (green edges: files with no errors; red 
% edges: files with errors; yellow edges: temporary files).


\begin{figure}
  \centering
    \includegraphics[width=\columnwidth]{images/pfs_barchart.png} \caption{Number 
    of occurrences of processes that create differences in PreFreeSurfer 
    among 100 subjects.} 
    \label{fig:pfs_chart}
  \end{figure}

\begin{figure}
\centering
  \includegraphics[width=\columnwidth]{images/pfs_frequency.png}
  \caption{Colorized processes along with the pipeline elements that introduce 
           differences. The range between red and green colors show the most and 
           least frequency of processes respectively.}
  \label{fig:pfs_freq}
\end{figure}


\subsubsection{FreeSurfer pipeline analysis} 
Result of FreeSurfer\dots



\section{Discussion}

\note{Pipeline amplify small numerical differences because they are numerically 
unstable. Furthermore, math libraries evolve over time, leading to 
different numerical errors. we listed some of the irreproducibility 
causes of the pipelines as we mentioned in the previous section 
overally along with exact command arguments.

Mention that this was only possible because the unprocessed data was 
shared in the first place. DICOM to Nifti conversion was out of scope 
and may introduce other issues.}

\section{Conclusion}

\note{Our technique is able to characterize the stability of a pipeline's 
components automatically. The numerical instability in the 
PreFreeSurfer HCP pipeline arises mainly from linear and non-linear 
registration processes implemented in FSL FLIRT and FNIRT. 

There are a few ways to impede such instabilities:
\begin{itemize}
\item Use a single operating system
\item Containerize pipelines
\item Increase numerical precision
\item Be stricter on truncation and rounding standards (IEEE 754)
\item Build static executable
\end{itemize}

The results still suffer from small perturbations literally because of 
the fact that pipeline are not numerically stable. The preferred 
solution is to detect and fix numerical instability of the pipeline 
instead of masking the problem. These processes need to be reviewed to 
understand and correct the cause of instabilities. 

It should be noted that processes that remove differrences, read files with differences and 
write files without differences, are not recognised 
by this method.
}


\section{Acknowledgments}

Data were provided by the Human Connectome Project, WU-Minn 
Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil; 
1U54MH091657) funded by the 16 NIH Institutes and Centers that support 
the NIH Blueprint for Neuroscience Research; and by the McDonnell 
Center for Systems Neuroscience at Washington University.

\note{CBRAIN team. Compute Canada(Calcul Quebec).}

\begin{figure*}
\centering
  \includegraphics[width=.9\textwidth]{images/graph}
  \caption{A complete process graph from the PreFreeSurfer pipeline.
Full-resolution image available at \url{https://drive.google.com/open?id=174yyn8SuVOUcK5aRVw0bagjDanLD0FLt}.}
  \label{fig:complete-graph}
\end{figure*}

\begin{figure*}
\centering
  \includegraphics[width=.8\textwidth]{images/hclusters}
  \caption{Different data types clustered among 100 subjects.}
  \label{fig:subj-clusters}
\end{figure*}



\bibliographystyle{plain}
\bibliography{biblio}


\end{document}
