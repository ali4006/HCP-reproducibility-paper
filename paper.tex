% GigaScience template
\documentclass[a4paper,num-refs]{oup-contemporary}

\journal{gigascience}


%%%% Packages %%%%
\usepackage{siunitx}
\usepackage{minted} % Used for JSON highlighting
\usepackage{algpseudocode} % Algorithmic environment
\usepackage{xspace}
\usepackage{booktabs}

%%%%%%

\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{makecell}
\usepackage[flushleft]{threeparttable}

\usepackage{subcaption}
\usepackage{xspace}
\usepackage{stmaryrd} % for llbracket and rrbracket
\usepackage{amsmath}
\DeclareMathOperator*{\argmin}{argmin}

%%%% Commands %%%%
\newcommand{\todo}[1]{\color{red}\textbf{TODO:}#1\color{black}}
\newcommand{\note}[2]{\color{blue}Note: #1\color{black}}
\newcommand{\reprozip}[0]{ReproZip\xspace}
\newcommand{\tristan}[1]{\color{blue}\textbf{From Tristan:}#1\color{black}}

 
\title{NURM: a tool to 
locate numerical differences in pipelines}
  
\begin{document}

\author[1]{Ali Salari}
\author[1]{Lalet Scaria}
\author[2,3]{Gregory Kiar}
\author[2]{Lindsay Lewis}
\author[2,3]{Alan C. Evans}
\author[1]{Tristan Glatard}

\affil[1]{Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada}
\affil[2]{McGill University, Montreal, Canada}
\affil[3]{Montreal Neurological Institute, Montreal, Canada}

\maketitle

\begin{abstract} 

Many experiments show that computational analysis results are still not 
completely reproducible. Computational environments including different 
operating systems, hardware categories, and software versions are known 
to have effects on the results produced by analysis pipelines. These 
effects are presumably due to the creation, propagation and 
amplification of small numerical differences across the pipelines. 
Although new techniques such as virtualization, version control 
systems, and provenance management tools provide more reliable 
environment and significantly improve the reproducibility of scientific 
findings. However, the precise causes of such instabilities and the 
path along which they propagate in the pipelines are unclear.  We 
present a technique to identify the processes in the pipeline that 
create numerical differences along the execution, and we apply this 
technique to the HCP structural pre-processing pipelines.

\end{abstract}

\begin{keywords}
Reproducibility; Numerical Instability; Neuroimaging.
\end{keywords}

\section{Introduction}

A reproducible study provides a context in which one is able to get 
results that are consistent with the original 
work~\cite{plesser2018reproducibility}. Research findings are expected 
to be reproducible so that their authenticity and reliability can be 
evaluated. 

Reproducibility is defined as the ability to regenerate the same 
results as the original findings when the experiment is reanalyzed by 
exactly the same analytic methods, software package, parameters, and 
data~\cite{peng2011reproducible}. 

In addition, numerical reproducibility is defined as the ability to 
regenerate bit for bit identical results from multiple 
runs~\cite{hill2017numerical}. This Numerical reproducibility can be 
checked by comparing the binary content of the results which is 
computed by the checksum method.
Regarding these definitions, it must be pointed that a
computation might be reproducible, but not 
be numerically reproducible. For instance, small numerical differences 
created during the pipeline execution may hamper numerical 
reproducibility, but be negligible in the final results.

\note{Recently, scientists began to realize that the results of many 
scientific experiments were not reproducible. 

In particular, validation of the reproducibility has been widely investigated 
in the field of neuroimaging in which uses optimized 
processing methods with the purpose of functional and/or structural 
assessments of the human brain.

According to the previous 
studies, variety of computational infrastructures including workstation 
types, parallelization methods, operating systems, and analysis 
packages are known to influence reproducibility~\cite{Gronenschild2012, 
diethelm2012limits, Glatard2015, bowring2019exploring}.

In particular, the effect of the operating system is quantified 
in~\cite{Glatard2015, Gronenschild2012} specially on some of the main 
neuroimaging pipelines including FSL, CIVET and FreeSurfer pipelines. 
The binary differences are measured by the checksum method between 
results of the same analyses on different operating systems, which 
indicate a significant disparity. 
}

These irreproducibility issues are reported as the result of the 
creation, propagation, and amplification of small numerical 
differences~\cite{Gronenschild2012, diethelm2012limits, Glatard2015, 
bowring2019exploring}. In this case, the analysis pipelines are said to 
be numerically unstable. Numerical instability is a characteristic of 
the pipelines which amplify small numerical differences and then hamper 
the reproducibility of the analyses depending on the length of the 
pipeline and magnitude of the differences. In many cases, numerical 
instability is an important issue for reproducibility.

There are different solutions to make reproducible analysis including 
containerization techniques that encapsulate software/hardware 
dependencies, provenance capturing tools, and version control systems. 
However, a comprehensive solution requires to fix the numerical 
instabilities. For this purpose, we introduce a Numerical 
Reproducibility Measurement (NURM) tool to identify the processes in 
the pipeline that create numerical differences across several runs. In this 
paper, the execution results of pipelines across different operating 
systems are considered to find out the cause of the irreproducibility 
using interposition techniques.

The remainder of this paper describes the NURM-tool in different parts 
including the way of capturing and representation of the provenance 
information, the method of clustering of different subject types, and 
process labelling to characterize differences. We describe the HCP 
preprocessing pipelines as a popular neuroimaging project to test the 
NURM-tool and evaluate its functionality. Finally, we reported the 
experimental results which describe the processes that are responsible 
for the differences in the pipelines.

\tristan{define subjects, explain neuroimaging, bring context.}
\section{Tool description}

Figure~\ref{fig:overview} shows an overview of our method. For each tested
condition, Condition 1 and Condition 2, the pipeline is containerized with
Docker, and its interface is described with
Boutiques~\cite{glatard2017boutiques}. \reprozip~\cite{Chirigati2016} is
added to Condition 1 for provenance tracking. Our tool starts by
identifying temporary files and ``multi-write" files, i.e., files written
by more than one process (Figure~\ref{fig:overview-capturing}). To do that,
the tool first executes the pipeline in Condition 1, to obtain a process
graph (Figure~\ref{fig:overview-capturing} - (1)) and a list of result files.
The list of processes that create intermediary or multi-write
files is then generated (Figure~\ref{fig:overview-capturing} - (2)). 
Using this list, the tool modifies Docker image in Condition 1 and
exectutes the pipeline again through it, which turns to produce results
including temporary and overwritten files
(Figure~\ref{fig:overview-capturing} - (3,4)). In the second step, the
processes are labeled from the differences found in their outputs in the
two tested conditions (Figure~\ref{fig:overview-labelling}). To this order,
the tool builds docker image for Condition 2 by modifying pipeline
processes (Figure~\ref{fig:overview-labelling} - (1)) that recognised from 
the process graph. Then, the modified docker
image is executed in Condition 2 and each process is labeled right after
the running by comparing the results obtained in Condition 1
and output files of the process in Condition 2
(Figure~\ref{fig:overview-labelling} - (2)). We then label processes in 2
categories depending whether they
create differences (represented in red) or not (green). 
The tool replaces output file with the same file obtained in Condition 1 
if process creates differences (Figure~~\ref{fig:overview-labelling} - (3)).
Process labelling
is done through hooks which are defined during the docker image modifying
procedure, and incremental updates in Condition 2, until the end of the
pipeline execution.

\begin{figure}
  \centering
  \begin{subfigure}{\columnwidth}
    \centering
    \includegraphics[width=1\columnwidth]{images/fig1-a}
    \caption{Identification of temporary and multi-write files.
    (\href{https://docs.google.com/drawings/d/1rsbFwPjNPNMRhXUl4RSK3G0OaiJC7K-buiHN0hPD8eQ/edit?usp=sharing}{Source})}
    \label{fig:overview-capturing}
  \end{subfigure}
   \begin{subfigure}{\columnwidth}
    \centering
     \includegraphics[width=1\columnwidth]{images/fig1-b}
     \caption{Labelling process graphs including intermediary files.
     (\href{https://docs.google.com/drawings/d/1yblYuKWAD18aJe5JxBu2h1EysyoQA3YrsQj-1T3s0l8/edit?usp=sharing}{Source})}
     \label{fig:overview-labelling}
   \end{subfigure}
   \caption{An overview of NURM tool in two steps. First capturing intermediary files (a); then
            labelling process graphs (b).}
   \label{fig:overview}
  \end{figure}

\subsection{Provenance capture and representation}

We use \reprozip 
to capture: (1) the set of processes created by the
pipeline, using the \texttt{clone()} or \texttt{fork()} system call, and
(2) the set of files read, written and executed by each process, including
temporary files. \reprozip collects this information through the
\texttt{ptrace()} system call and stores it in a SQLite database.

Our tool reconstructs a \emph{process tree} starting from the first process
created by the pipeline and traversing processes through \texttt{clone()}
and \texttt{fork()} dependencies. Our tool also creates a process \emph{graph} 
(Figure~\ref{fig:overview-capturing} - (1)) from this tree
by adding edges corresponding to file dependencies between processes. A
file dependency is defined between processes A and B if a file written by A
is read by B. Figure~\ref{fig:simple_script} shows an example of a process
tree and graph constructed from the example pipeline in
Listing~\ref{listing:sample-script}.
\begin{listing}
\begin{minted}[frame=single,
  framesep=3mm,
  linenos=false,
  xleftmargin=0pt,
  tabsize=4]{bash}
#!/bin/bash

# This script extracts the brain from an input image,
# measures the volume of the extracted brain,
# and creates a binarized brain mask.

if [ $# != 1 ]
then
    echo "usage: $0 <inputimage.nii.gz>"
    exit 1
fi

# Parse argument, set file names
input_image=$1
bet_output=$(basename "${input_image}" \
                       .nii.gz)_brain.nii.gz
bet_output_binarized=$(basename "${input_image}" \
                       .nii.gz)_brain_bin.nii.gz

# Run FSL bet, put result ${bet_output}
bet "${input_image}" "${bet_output}" > bet_temp.out
echo "Voxels / Volume in brain mask:"
# Run FSL stats on ${bet_output}
fslstats "${bet_output}" -V
# Run FSL maths on ${bet_output}
fslmaths "${bet_output}" "${bet_output_binarized}"
# Remove temporary file
\rm bet_temp.out
\end{minted}
  \caption{Example pipeline}
  \label{listing:sample-script}
\end{listing}

\begin{figure}
\centering
  \includegraphics[width=0.3\columnwidth]{images/simple_graph}
  \caption{Process tree and graph
  constructed from the example pipeline in
  Listing~\ref{listing:sample-script}.
  Processes that read or write
  temporary files are 
  represented with squares. Plain edges 
  represent the process tree (\texttt{fork()} or \texttt{clone()} 
  system calls). Dashed edges represent file dependencies: temporary 
  files are in yellow and result files are in green.
  Every node in the tree is labeled using (1) a process id created by our
  reconstruction, (2) the name of the executable run by the process.
  Process 0 is the initial call to the \texttt{sh} interpreter, and
  processes 1, 3 and 4 are the calls to FSL bet, stats and maths made in
  Listing~\ref{listing:sample-script}. Process 2 is forked by process 1: it
  was captured by \reprozip while it did not appear in
  Listing~\ref{listing:sample-script}. 
}
  \label{fig:simple_script}
\end{figure}


\subsection{Graph analysis}

We label in two categories the processes of the graph of each subject. First,
processes that read files that do not have differences and write files that
do not have differences are labeled \emph{transparent}
(Figure~\ref{fig:green}). Second, processes that read files that do not
have differences but write files that have differences \emph{create}
differences (Figure~\ref{fig:red}). In addition, processes that read files
that have differences and write files that also have differences are called
\emph{undetermined} (Figure~\ref{fig:yellow}). Processes are also labeled
undetermined when they read or write temporary files, or produce multi-write
files. To resolve undetermined processes, hooks must be added to the pipeline to 
execute these processes on files without differences, and to capture
intermediary file states.

\begin{figure}%\centering
\centering
    \begin{subfigure}{0.2\linewidth}
        \includegraphics[scale=0.3]{images/green.png}
        \caption{Transparent}
        \label{fig:green}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.2\linewidth}
    \includegraphics[scale=0.3]{images/red.png}
    \caption{Creates differences}
    \label{fig:red}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.2\linewidth}
    \includegraphics[scale=0.3]{images/yellow.png}
    \caption{Undetermined}
    \label{fig:yellow}
\end{subfigure}
    \caption{Different type of labeled process based on the input/output files.
  Dashed edges refer to the file dependencies between processes A and B 
  if a file written by A is read by B. Solid black edges refer to the 
  relationship between parent and child processes.}
    \label{fig:processes}
\end{figure}

\subsubsection{Capturing temporary files} 

The label of processes that read or 
write temporary files is undetermined because these files are deleted during 
the execution. To address this issue, we replace in Condition 1 every process P that 
writes temporary files by a wrapper that first calls P and then
saves all its output files to a read-only directory. This replacement is
done by modifying the PATH environment variable to point to a directory
containing a modified version of the executable called by the process. The
modified executable will run the original executable and then save its
output files (see Listing~\ref{listing:modify-script}). 
This 
solution does not cover the temporary files that are removed by P 
itself, but this is not a problem since these files do not play any role in 
the subsequent steps of the pipeline. 

\begin{listing}
  \begin{minted}[frame=single,
    framesep=3mm,
    linenos=false,
    xleftmargin=0pt,
    tabsize=4]{python}
  #!/usr/bin/env python
  import os.path as op
  import shutil
  import pipes

  # Run the original executable using the same arguments
  executed_file = sys.argv[0]
  exec_argv = op.join('original_scripts', executed_file)
  exec_argv = exec_argv + " ".join(map(pipes.quote, sys.argv[1:]))
  subprocess.Popen(exec_argv, shell=True).communicate()
  
  # Load list of captured process to be checked
  with open('path/to/p_list/', 'r') as p_list:
      process_list = json.load(p_list)

  if exec_argv in process_list.keys():
      # Save output files to read-only directory
      p_files = process_list[exec_argv]
      shutil.copy(p_files, '/read-only/dir')
  
  \end{minted}
    \caption{Modified version of the script in Listing~\ref{listing:sample-script} to save intermediary files.}
    \label{listing:modify-script}
  \end{listing}

\subsubsection{Capturing multi-write files}

Files written by multiple processes also lead 
to undetermined labels. For a file F 
written by all processes in \textbf{P} = \{$P_{1}$, \ldots $P_{n}$\}, we 
(1) check that processes in \textbf{P} do not write concurrently to F, 
(2) we establish an order on \textbf{P} based on the creation timestamp 
of the processes, (3) we replace every process $P_{i}$ in \textbf{P} by 
a wrapper that first calls $P_{i}$ and then saves F to a read-only 
directory. Thus, multiple versions of F are saved and used in the 
analysis. 

Furthermore, cycles may be present in the process graph in case a file 
was written by more than one process. We remove such cycles by removing 
file edges between processes A and B when A's process creation 
timestamp is posterior to B's or when A=B. Indeed, such edges cannot 
happen in practice unless A and B were running concurrently, which we 
assume is not the case (the tool checks for that). 

As an example of this capturing process, in the sample pipeline in 
Listing~\ref{listing:sample-script}, process \texttt{2\#bet2} writes a temporary file and 
also file \emph{T1w\_brain\_bin.nii.gz} is first written by process \texttt{2\#bet2} and 
then overwritten by process \texttt{3\#fslmaths}. The list of these processes is captured in 
Listing~\ref{listing:json_process}.
Using this list, we modify relevant processes in Condition 1 and then re-execute pipeline 
to save them in a backup folder.
Figure~\ref{fig:overview-capturing} - (4) shows pipeline results including intermediary files 
captured as the outputs in Condition 1. 

\begin{listing}
  \begin{minted}[frame=single,
    framesep=3mm,
    linenos=false,
    xleftmargin=0pt,
    tabsize=4]{JSON}
{
  "multi_write_process": {
    "fslmaths\00T1w_brain.nii.gz\00T1w_brain_bin.nii.gz":
    {
      "files":[
        "/cond1/subj1/T1w_brain_bin.nii.gz"
      ],
      "pid": 78
    },
    "bet2\00/cond1/subj1/T1w.nii.gz\00T1w_brain.nii.gz":
    {
      "files":[
        "/cond1/subj1/T1w_brain_bin.nii.gz"
      ],
      "pid": 75
    }
  },
  "temp_process": {
    "bet2\00/cond1/subj1/T1w.nii.gz\00T1w_brain.nii.gz": 
    {
      "files": [
        "/cond1/subj1/temp.tmp"
      ],
      "pid": 75
    } 
  } 
}

\end{minted}
\caption{List of process and their files from the example pipeline in 
Listing~\ref{listing:sample-script} that should be captured.}
\label{listing:json_process}
\end{listing}


\subsubsection{Labelling undetermined processes} 

Since all the result files are captured in Condition 1, the tool 
is ready to label the piepeline processes based on the results in Condition 2.
However, another challenge is to label undetermined processes that read files with 
differences and write files with differences too. In this
situation, it is not possible to determine from the pipeline results 
whether the process created differences or 
was transparent.
To address this issue, we set hooks in the pipeline 
in Condition 2. Hooks are set by replacing the pipeline 
processes with a custom script. This custom script labels each process 
as \emph{transparent} or \emph{create differences} immediately after running 
the original executable. 
The replacement is done through the PATH variable, as before. Moreover, 
this custom script copies the results obtained from the same process in 
Condition 1 to the pipeline output in Condition 2 if 
it is invoked with the arguments of a process that created differences 
(Figure~\ref{fig:overview-labelling} - (3)). 
Differences are identified by comparing checksum of the output files for 
the same process in both conditions (Figure~\ref{fig:overview-labelling} - (2)).
We developed an incremental approach that consists of the following steps: 

\begin{enumerate}
  \item Start the pipeline execution in Condition 2; 
        after hooking all the processes involved in the pipeline.
  \item Label each process as \emph{transparent} or \emph{create differences} 
        right after its running.
  \item Check if process is \emph{create differences} then: 
        copy the results produced by the same process in Condition 1 to the 
        pipeline output in Condition 2. 
  \item Continue steps 2 and 3 until the end of the pipeline execution.
\end{enumerate}

This algorithm creates a \emph{labeled process tree} at the end of pipeline execution 
which highlights processes that create differences.
(Figure~\ref{fig:overview-labelling} - (4)).

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{images/iterative_modif}
  \caption{A simple example of steps of the proposed approach.}
  \label{fig:iterations}
\end{figure}

Figure~\ref{fig:iterations} illustrates our incremental labelling 
process for the example in Figure~\ref{fig:simple_script}. At every 
step, processes that created differences are shown in red and other processes 
(transparent processes) are in green. As in 
Figure~\ref{fig:simple_script}, plain black edges represent the process 
tree and dashed edges represent file dependencies: green edges 
represent files with no differences, while red edges represent files with 
differences. Temporary files are not represented because they have been 
saved as previously described.

The four steps in Figure~\ref{fig:iterations} correspond to the 
steps of the labelling algorithm. 
At step one, process \texttt{1\#bet} is executed and then labeled 
as transparent (green) as it produced files without differences.
At step 2, \texttt{2\#bet2} 
is labeled as difference creator (red) as it produced files with differences 
from files without differences. Therefore, the files produced by \texttt{2\#bet2} in  
Condition 2 are replaced with the files produced by \texttt{2\#bet2} in 
Condition 1.
At step 3, after running process \texttt{3\#fslstats}, it labeled as 
transparent as it write files without differences.
At step 4, process \texttt{4\#fslmaths} is labeled as difference creator 
as the last process of the pipeline.
As a result of these 4 steps, the final process labelling is: 
\texttt{2\#bet2} and \texttt{4\#fslmath} are difference creators (red) 
and the other processes are transparent.


\subsection{Subject clustering}

Different subjects may lead to different \emph{process tree}, due to
variations that may be coming from differences in data types or
cardinality. For instance, some images may have been acquired multiple
times in some subjects. Some of these differences can be neglected, for
instance when a data decompression step is present at the beginning of the
execution for some subjects only, and other ones cannot, when different
processing paths are used in different subjects.

Different \emph{process tree} shows that pipeline execution followed by a different procedure. 
This implies the possible impact of different subjects on pipeline results.
We cluster subjects into different types to specify how many different 
\emph{process trees} are generated. Clustering is performed based on the \emph{process trees} 
which nodes are labeled by the process name. 
In this order, 
the tree edit distance~\cite{zhang1989simple} is used as a similarity measure for 
representing the distance between labeled trees. Tree edit distance  is defined  
as the minimum number of edit operations which is needed to transform one tree into 
the other. Three edit operations are considered: node label modification, 
node removal, and node insertion. Each operation has an associated cost of 1.
With this distance, we cluster subjects using agglomerative hierarchical
clustering as implemented in SciPy~\cite{oliphant2007scipy}
(Algorithm~\ref{algo:hclustering}). As a result, the distance between
any two subjects in a cluster is lower than a threshold parameter.

Furthermore, we will show that even subjects in the same cluster, 
having the same topological \emph{process tree} structure, 
may have different labels as processes that create differences.

\begin{algorithm}[h!]
\caption{Hierarchical clustering algorithm from SciPy}
\label{algo:hclustering}
\begin{algorithmic}

  \State /* Input: - a list of n trees; \texttt{T = [t${_1}$, t${_2}$,...,t${_n}$]}
  \State /*\quad \quad \quad \quad - a distance threshold value; \texttt{threshold}
  \State /* Output: a list of clusters; \texttt{C = [c${_1}$,c${_2}$,...,c${_k}$]}
  \State \texttt{\# Create a cluster for each tree in input list;}
  \State \texttt{C = [ [t${_1}$], [t${_2}$], \ldots , [t${_n}$] ]}
  \State \texttt{\# Define a 2 $\times$ 2 array to store distances}
  \State \texttt{D} = \texttt{array(n, n)}
  \While{\texttt{len(C)} > \texttt{1}}  
  \State \texttt{\# Select the two nearest clusters}
  \For{\texttt{i=1} to \texttt{n}}
  \For{\texttt{j=i+1} to \texttt{len(C)}}
  \State \texttt{D[i][j]} = $\min \left\{ \texttt{edit\_dist(a, b)}: \ \texttt{a} \in \texttt{C[i]}, \texttt{b} \in \texttt{C[j]} \right\}$
    \EndFor
  \EndFor
  \State \texttt{i, j} = $\argmin \left\{ \texttt{D[i][j]}, \ \texttt{i, j} \in \llbracket 1, \texttt{len(C)}\rrbracket^2 \right\}$
  \If{\texttt{D[i][j]} > \texttt{threshold}}
  \State \Return \texttt{C}
  \Else
  \State \texttt{\# Merge C[j] into C[i]}
  \State \texttt{C[i]} = \texttt{merge}(\texttt{C[i] and C[j]})
  \State \texttt{\# Remove C[j] from C}
  \State \texttt{remove(C[j], C)}
  \EndIf
  \EndWhile
%  \State Function edit\_distance (C${_1}$, C${_2}$)
%  \State EndFunction
\end{algorithmic}
\end{algorithm}

\section{Experiments}

The variety of computing infrastructures, particularly the operating system, are 
known to influence the reproducibility of computational pipelines because of the
creation of small numerical differences. 
These differences mainly correspond to the mathematical functions implemented 
in different operating system libraries.
For instance, changing the mathematical functions like \emph{expf()} and 
\emph{cosf()} which manipulate the precision of floating-point representations, 
between \emph{glibc} libraries in different operating systems can produce 
small numerical differences.
Furthermore, a similar issue is expected for any operating system which is 
based on \emph{glibc}, the GNU C library.

Indeed, the propagation and amplification of these tiny perturbations by analysis 
may cause reproducibility issues. We focus on the differences 
created by different version of operating systems in computational pipelines. 
In particular, NURM-tool is tested on the neuroimaging applications which are 
predominantly using mathematical libraries.

\subsection{HCP pipelines and datasets}

We used our tool to evaluate the effect of the operating system on results 
produced by the pipelines from the Human Connectome Project (\href{https://www.humanconnectome.org}{HCP}).
The HCP initiative is a significant effort that will acquire and analyze 
brain connectivity data from 1200 healthy adults.
It enables the neuroscience 
research community to discover relationships between brain circuits and 
individual behaviors. This helps to understand a wide range of brain disorders.
The HCP project provides (1) database services (ConnectomeDB) for storing and 
sharing primary and processed data freely, and (2) data analysis pipelines that 
are available under an open source license.

The HCP developed a set of pre-processing pipelines to process structural,
functional and diffusion MRI data acquired in the project. We focus on HCP
pre-processing pipelines for structural data, particularly PreFreeSurfer
and FreeSurfer. 

According to~\cite{glasser2013}, main steps of the HCP PreFreeSurfer pipeline are:
(1) Distortion Correction: 
is the correction of geometric distortions for routine MRI scans 
to produce an undistorted native structural volume space for each subject.
(2) Anatomical Average: average same modality images (if more than one is available)
(3) ACPC (Anterior Commissure, Posterior Commissure) Alignment: 
is aligning images to the MNI space to have the same orientation as 
the reference template.
(4) Brain Extraction: includes a robust initial brain extraction, using FSL's linear (FLIRT) 
and non-linear (FNIRT) registration. 
(5) Bias Field Correction: applies intensity inhomogenity correction on the registered images.
Calculates bias field using square root of the product of T1w and T2w images. 
(6) Atlas-Registration: register the subject's native structural volume space to MNI space as the last step.

Also, the main goals of HCP FreeSurfer pipeline are:
(1) improve the robustness of brain extraction,
(2) fine tune image registration,
(3) accurately place the surface images with high resolution data,
(4) perform FreeSurfer's standard folding-based surface registration 
to their surface atlas.

A detailed description of the analyses done in the
pipelines is available in~\cite{glasser2013}. 

HCP data consists of brain images collected from an individual healthy person, 
in the age range from 22-35 years~\cite{van2013wu}. Data from 1200 subjects 
is available in \href{https://db.humanconnectome.org}{the ConnectomDB repository}. 
Such a directory containing the HCP data is denoted by the term ``subject".
In this paper, we randomly selected 100 unprocessed subjects from 
the HCP data release S500. All the subjects were scanned using the 3-tesla 
type of MRI scanners.


\subsection{Processing of data}

We executed the pipelines using Docker containers to simplify the 
deployment of different operating system versions on execution 
platforms. 
The Docker images were built for the HCP pre-processing 
pipelines v3.19.0 (PreFreeSurfer and FreeSurfer) in 
CentOS 6.9 (Final) and CentOS 7.4 (Core). 
CentOS is a widely used operating system among the Neuroscience community because of 
the appropriate community support, network functions, safety, portability, and openness
~\cite{hanke2011neuroscience}.
These containers were installed with all the necessary software and libraries 
required to run the HCP pipelines including FSL (version 5.0.6), 
FreeSurfer (version 5.3.0-HCP, CentOS4 build), and Connectome Workbench (version 1.0).
Docker images are available on 
\href{https://hub.docker.com/r/bigdatalabteam/hcp-prefreesurfer/}{DockerHub}
for reuse.

The data were processed in the order PreFreeSurfer and FreeSurfer. 
Unprocessed subject data used as the input data for PreFreeSurfer and its output 
results used as the input data for FreeSurfer analysis in each operating system separately.
Through all the subjects, first, two runs were made on the same operating systems 
to be sure that identified differences are not coming from the operations with randomness.
Then we identified the processes in the pipelines that are responsible for 
the creation of differences using the NURM-tool.

It should be noted that some files may have the same data but 
different metadata in headers, including creation time, modification time and date, 
which turns to non-identical checksums. 
So, we added some other functions for the file comparison to be sure that differences 
are in part of the file data. 
Depending on the file type, we used functions from FreeSurfer software package to determine 
whether two files differ, including  
\emph{mri\_diff}, \emph{mris\_diff}, and \emph{lta\_diff} for comparing volumes, surface-based files, 
and lta files (transforms) respectively. Also, text files are compared using a custom function.

\subsection{Results}

Two types of differences can occur in the subjects due to the 
differences in the operating systems. One is inter-OS differences caused by the 
operating system library updates and the other type, intra-OS differences 
occur as a result of the pseudo-random processes used in the 
pipelines. 

In our experiments, we identified the processes that create differences due to 
using random variables in the FreeSurfer pipeline. 
For example, process \emph{mris\_curvature}
computes mean and Gaussian curvatures of a cortical surface using the random variable.
To avoid such randomness we 
initialized random number generators using a seed state in 
the command line in which pipeline script calls the program.
This ensures that results are the same from run to run.
Therefore, NURM-tool can identify the process in the pipelines 
that create differences caused by the inter-OS differences. 

\subsubsection{Inter-OS binary differences}

In a previous study~\cite{Scaria2017}, we showed that the HCP pre-processing 
pipelines~\cite{glasser2013} were 
sensitive to operating system variation. 

Figure~\ref{fig:fnirt_result} shows differences in the \emph{T2w\_acpc\_to\_MNI\_nonli.nii.gz} files. 
These files are created as a part of ACPC-Alignment (Step 3 of PreFreeSurfer).
The RMSE (root mean squared error) value of results is 0.029 and the dice coefficient is 0.125.
The square pixels in the brain in this checkerboard images show the differences between results in two OSes. 
In the next subsection, we will show that such misalignment is created due to 
non-linear registration in \emph{FNIRT} process in PreFreeSurfer pipeline.

Furthermore, Figure 
\ref{fig:tissue_class} illustrates the binarized differences in the \emph{aseg.hires.mgz} files.
This is the result of brain tissue segmentation across OSes in FreeSurfer pipeline. 
Each color represents a different structure in the brain.
The bright spots show relevant pixels in the image which are different.
The RMSE and the dice coefficient values of results are 0.009 and 0.991 respectively.


\begin{figure}
  \centering
    \includegraphics[width=\columnwidth]{images/segmentation.png} 
    \caption{Differences between FNIRT results from PreFreeSurfer 
    (checkerboard image \emph{T2w\_acpc\_to\_MNI\_nonli.nii.gz}) (CentOS6 vs. 
    CentOS7). Right images show the zoomed version part of the images marked 
    by the red rectangle.} 
    \label{fig:fnirt_result}
\end{figure}

\begin{figure}
%  \includegraphics{brain\_classification}
\centering
  \includegraphics[width=\columnwidth]{images/brain_classification.png} 
  \caption{Binarized differences between brain segmentation results from 
           FreeSurfer (CentOS6 vs. CentOS7).} 
  \label{fig:tissue_class}
\end{figure}


\subsubsection{PreFreeSurfer pipeline analysis} 

First, subjects are clustered into different groups using the clustering method as described before.
We choosed the threshold value of zero for the clustering method. 
This turns to have the subjects with the same topology in each cluster.
Also, we used the nearest neighbor algorithm to calculate the distance between clusters.
Table~\ref{table:data-clusters} shows the PreFreeSurfer result of subject clustering. 
Among our dataset, we identified 4 types of subjects with 
different topology of \emph{process trees}. 
Differences correspond to the data processing that leads to producing disparate output file(s).
For example, subject type 3 missed output file \emph{T1w2\_gdc.nii.gz} after processing 
in comparison with subject type 1.
Besides, we verified that 
the \emph{process trees} were identical for all subjects of the same type in 
different versions of CentOS.

\begin{table}
\centering
\begin{threeparttable}
\caption{Clustering of 20 input subjects.}

\begin{tabular}{@{}llllll@{}}
\toprule
Type   & Number of Subjects  & Missing File(s)                                    \\ \midrule
type1  & 9                   & None                                               \\
type2  & 7                   & [``T1w/T1w2\_gdc.nii.gz",                          \\
       &                     &  ``T2w/T2w2\_gdc.nii.gz"]                          \\
type3  & 2                   & [``T1w/T1w2\_gdc.nii.gz"]                          \\
type4  & 2                   & [``T2w/T2w2\_gdc.nii.gz"]                          \\ \bottomrule
\end{tabular}
\begin{tablenotes}
     \small
     \item *Type refers to the topology type of the \emph{process tree} of subjects.
\end{tablenotes}
\end{threeparttable}
\label{table:data-clusters}
\end{table}


Then, we determined the frequency of the processes that create differences in 
the pipeline in Figure~\ref{fig:pfs_freq}. \emph{FLIRT} is the most frequent 
process that produces differences.
Furthermore, the percentage of processes that introduce differences 
in PreFreeSurfer along with the 
pipeline elements are depicted in Figure~\ref{fig:pfs_freq} 
including linear registration with “\emph{FLIRT}” (in 
ACPC-Alignment, BrainExtraction, DistortionCorrection, 
AtlasRegistration), non-linear registration with “\emph{FNIRT}” (in 
BrainExtraction and AltasRegistration), image warping with 
“\emph{new\_invwarp}” (in BrainExtraction and AtlasRegistration). 
Also, differences were observed in image mean and standard-deviation 
computations in image interpolation with “\emph{fslmaths}” (in AnatomicalAverage). 
It can be seen that \emph{fslmaths} and \emph{FLIRT} 
are the processes that at least have one subprocess to produce differences across all the subjects.


% \begin{figure}
%   \centering
%     \includegraphics[width=\columnwidth]{images/pfs_barchart.png} \caption{Number 
%     of occurrences of processes that create differences in PreFreeSurfer 
%     among 20 subjects.} 
%     \label{fig:pfs_chart}
%   \end{figure}

\begin{figure}
\centering
  \includegraphics[width=\columnwidth]{images/pfs_heatmap.png}
  \caption{Colorized processes along with the pipeline elements that introduce 
           differences among 20 subjects. The range between red and green colors show the most and 
           least frequency of processes respectively. Besides, the number 
           of occurrences of each processes with differences is represented in the line below the heatmap.}
  \label{fig:pfs_freq}
\end{figure}


\subsubsection{FreeSurfer pipeline analysis} 

We found that inter-OS differences occur if pre-processed data are different in FreeSurfer. 
Figure~\ref{fig:tissue_class} shows differences that coming from PreFreeSurfer analysis 
as a result of propagation of differences. 
NURM tool identified that there are no processs in the pipeline that create differences.
This is because of using static builds of FreeSurfer which statically linked libraries (embeded libraries in the pipeline).


\section{Discussion}

\note{Pipelines amplify small numerical differences because they are numerically 
unstable. Furthermore, math libraries evolve over time, leading to 
different numerical errors. we listed some of the irreproducibility 
causes of the pipelines as we mentioned in the previous section 
overally along with exact command arguments.

Mention that this was only possible because the unprocessed data was 
shared in the first place. DICOM to Nifti conversion was out of scope 
and may introduce other issues.}

\section{Conclusion}

\note{Our technique is able to characterize the stability of a pipeline's 
components automatically. The numerical instability in the 
PreFreeSurfer HCP pipeline arises mainly from linear and non-linear 
registration processes implemented in FSL FLIRT and FNIRT. 

There are a few ways to impede such instabilities:
\begin{itemize}
\item Use a single operating system
\item Containerize pipelines
\item Increase numerical precision
\item Be stricter on truncation and rounding standards (IEEE 754)
\item Build static executable
\end{itemize}

The results still suffer from small perturbations literally because of 
the fact that pipeline are not numerically stable. The preferred 
solution is to detect and fix numerical instability of the pipeline 
instead of masking the problem. These processes need to be reviewed to 
understand and correct the cause of instabilities. 
}


\section{Acknowledgments}

Data were provided by the Human Connectome Project, WU-Minn 
Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil; 
1U54MH091657) funded by the 16 NIH Institutes and Centers that support 
the NIH Blueprint for Neuroscience Research; and by the McDonnell 
Center for Systems Neuroscience at Washington University.

\note{CBRAIN team. Compute Canada(Calcul Quebec).}

% \begin{figure*}
% \centering
%   \includegraphics[width=.9\textwidth]{images/graph}
%   \caption{A complete process graph from the PreFreeSurfer pipeline.
% Full-resolution image available at \url{https://drive.google.com/open?id=174yyn8SuVOUcK5aRVw0bagjDanLD0FLt}.}
%   \label{fig:complete-graph}
% \end{figure*}

% \begin{figure*}
% \centering
%   \includegraphics[width=.8\textwidth]{images/hclusters}
%   \caption{Different data types clustered among 100 subjects.}
%   \label{fig:subj-clusters}
% \end{figure*}



\bibliographystyle{plain}
\bibliography{biblio}


\end{document}
